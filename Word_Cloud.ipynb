{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNZ5EQ4CHvE64D9+uM9HorF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yasaman-habibi/Pre_Processing_Report/blob/main/Word_Cloud.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wordcloud"
      ],
      "metadata": {
        "id": "lBh5hH4mjikk",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfSbPex82a6A"
      },
      "outputs": [],
      "source": [
        "#Import Library\n",
        "\n",
        "import os\n",
        "import re\n",
        "import nltk\n",
        "import glob\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive, files\n",
        "from google.colab import drive\n",
        "import ipywidgets as widgets\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from wordcloud import WordCloud"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Upload Files\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "source_path = \"/content/drive/MyDrive/Combined_Texts\"\n",
        "all_txt_files = glob.glob(os.path.join(source_path, \"*.txt\"))\n",
        "\n",
        "selector = widgets.SelectMultiple(\n",
        "    options=all_txt_files,\n",
        "    description='Select files',\n",
        "    rows=10\n",
        ")\n",
        "display(selector)"
      ],
      "metadata": {
        "id": "qqY4jrYi2g20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded_Texts = list(selector.value)\n",
        "print(\" انتخاب شد:\\n\" + \"\\n\".join(uploaded_Texts))"
      ],
      "metadata": {
        "id": "M_Nsp7EU2imV",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function\n",
        "\n",
        "def process_reports_tagged_and_wordcloud(uploaded_Texts, sustain_terms, wordcloud_path):\n",
        "    records = []\n",
        "\n",
        "    sustain_terms = sorted(set([kw.strip().lower() for kw in sustain_terms]),\n",
        "                           key=lambda x: len(x.split()), reverse=True)\n",
        "\n",
        "    for file_path in uploaded_Texts:\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            content = f.read()\n",
        "\n",
        "        pattern = r\"===== Start of File: (.+?) =====\\n(.*?)\\n===== End of File: \\1 =====\"\n",
        "        reports = re.findall(pattern, content, flags=re.DOTALL)\n",
        "\n",
        "        for report_name, report_text in reports:\n",
        "            text = report_text.lower()\n",
        "            counts = {}\n",
        "\n",
        "            for term in sustain_terms:\n",
        "                term_pattern = r\"\\b\" + re.escape(term) + r\"\\b\"\n",
        "                matches = list(re.finditer(term_pattern, text))\n",
        "                if matches:\n",
        "                    counts[term] = len(matches)\n",
        "                    text = re.sub(term_pattern, \" \" * len(term), text)\n",
        "\n",
        "            for kw, cnt in counts.items():\n",
        "                records.append({\"report_name\": report_name, \"keyword\": kw, \"count\": cnt})\n",
        "\n",
        "    df = pd.DataFrame(records)\n",
        "\n",
        "    df[\"report_name\"] = df[\"report_name\"].str.replace(r\"\\s*\\(\\d+\\)$\", \"\", regex=True)\n",
        "    df = df.drop_duplicates()\n",
        "\n",
        "    os.makedirs(wordcloud_path, exist_ok=True)\n",
        "\n",
        "    # Create Function\n",
        "    def create_wordcloud_from_freq(freq_dict, title, save_path):\n",
        "        wc = WordCloud(width=1600, height=1200,background_color=\"white\",colormap=\"viridis\",max_words=150,min_font_size=14)\n",
        "\n",
        "        wc.generate_from_frequencies(freq_dict)\n",
        "        plt.figure(figsize=(10,7))\n",
        "        plt.imshow(wc, interpolation=\"bilinear\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(title, fontsize=18)\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    # WordCloud\n",
        "    total_freq = df.groupby(\"keyword\")[\"count\"].sum().to_dict()\n",
        "    create_wordcloud_from_freq(total_freq, \"All Reports\", os.path.join(wordcloud_path, \"wordcloud_all_keywords.png\"))\n",
        "\n",
        "\n",
        "    # Word cloud year by year\n",
        "    df_reset = df.reset_index(drop=True)\n",
        "    df_reset['year'] = df_reset['report_name'].str[:4]\n",
        "    years = df_reset['year'].unique()\n",
        "\n",
        "    for year in years:\n",
        "        df_year = df_reset[df_reset['year'] == year]\n",
        "        freq = df_year.groupby(\"keyword\")[\"count\"].sum().to_dict()\n",
        "        create_wordcloud_from_freq(freq, f\"Word Cloud for Year {year}\",\n",
        "                                   os.path.join(wordcloud_path, f\"wordcloud_keywords_{year}.png\"))\n",
        "\n",
        "    print(\" وردکلادها ساخته و ذخیره شدند.\")\n",
        "    return df"
      ],
      "metadata": {
        "id": "jOd8uu50PID6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sustain_Dic = pd.read_excel(\"/content/drive/MyDrive/sustainability_table/PivotReport/keywords.xlsx\")\n",
        "keywords = sustain_Dic[\"keyword\"].dropna().str.strip().tolist()\n",
        "\n",
        "wordcloud_path = \"/content/drive/MyDrive/sustainability_table/wordclouds\"\n",
        "os.makedirs(wordcloud_path, exist_ok=True)"
      ],
      "metadata": {
        "id": "5EKF0MKuQ-vP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pivot_df = process_reports_tagged_and_wordcloud(uploaded_Texts, keywords , wordcloud_path)"
      ],
      "metadata": {
        "id": "pFFsx_rvRUDa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}