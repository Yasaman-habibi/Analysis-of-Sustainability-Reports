{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yasaman-habibi/Pre_Processing_Report/blob/main/Filtered_Data_By_KeyWords.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEjtTaENL7Ed"
      },
      "outputs": [],
      "source": [
        "#Import Library\n",
        "from google.colab import files, drive\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "import io\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bW0CG1o0AzPa",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#Upload Files\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "uploaded_Texts = files.upload()\n",
        "Combined_path = \"/content/drive/MyDrive/Combined_Texts\"\n",
        "os.makedirs(Combined_path, exist_ok=True)\n",
        "Combined_file = os.path.join(Combined_path, \"Combined_Texts.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5mmxr9TnSe3"
      },
      "outputs": [],
      "source": [
        "#Upload Files\n",
        "\n",
        "df_dict = pd.read_excel(\"/content/drive/MyDrive/sustainability_table/Loughran-McDonald.xlsx\")\n",
        "keywords = pd.read_excel(\"/content/drive/MyDrive/sustainability_table/keywords.xlsx\")\n",
        "sustain_Dic = pd.read_excel(\"/content/drive/MyDrive/sustainability_table/sustain_Dic.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IkEJDJCMoMH"
      },
      "outputs": [],
      "source": [
        "#Reading text files to perform processing\n",
        "\n",
        "text = \"\"\n",
        "for filename in uploaded_Texts.keys():\n",
        "    with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
        "        text += file.read() + \"\\n\\n\"\n",
        "\n",
        "def split_paragraphs(text):\n",
        "    paragraphs = [p.strip() for p in re.split(r'\\n\\s*\\n', text) if p.strip()]\n",
        "    return paragraphs\n",
        "\n",
        "paragraphs = split_paragraphs(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpIDYCpcc6wj"
      },
      "outputs": [],
      "source": [
        "#Filtering text using a dictionary built based on Keywords\n",
        "sustain_terms = set(sustain_Dic[\"Word\"].dropna().str.lower())\n",
        "\n",
        "\n",
        "#Process for a word or multiple words as a phrase in a keyword list\n",
        "sustain_terms_raw = sustain_Dic[\"Word\"].dropna().str.strip().str.lower().tolist()\n",
        "single_terms = set(term for term in sustain_terms_raw if len(term.split()) == 1)\n",
        "multi_terms = set(term for term in sustain_terms_raw if len(term.split()) > 1)\n",
        "\n",
        "\n",
        "def contains_sustain_terms(paragraph):\n",
        "    para_lower = paragraph.lower()\n",
        "    #  multiple words\n",
        "    padded_para = f\" {para_lower} \"\n",
        "    match_multi = any(f\" {term} \" in padded_para for term in multi_terms)\n",
        "    #  a word\n",
        "    words_in_para = re.findall(r'\\b\\w+\\b', para_lower)\n",
        "    match_single = any(word in single_terms for word in words_in_para)\n",
        "    return match_multi or match_single\n",
        "\n",
        "\n",
        "#Filter paragraphs related to sustainability\n",
        "filtered_paragraphs = [para for para in paragraphs if contains_sustain_terms(para)]\n",
        "print(f\"{len(filtered_paragraphs)} paragraphs contain sustainability-related terms.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HK5kC-kjzkm"
      },
      "outputs": [],
      "source": [
        "#Combine only paragraphs related to sustainability\n",
        "\n",
        "Combined_Sustain_text_path = os.path.join(Combined_path, \"Combined_Sustain_text.txt\")\n",
        "\n",
        "def get_next_index(base_path, prefix=\"Combined_Sustain_text_\", suffix=\".txt\"):\n",
        "    existing_files = os.listdir(base_path)\n",
        "    indices = []\n",
        "\n",
        "    for fname in existing_files:\n",
        "        match = re.match(fr\"{re.escape(prefix)}(\\d+){re.escape(suffix)}\", fname)\n",
        "        if match:\n",
        "            indices.append(int(match.group(1)))\n",
        "    return max(indices, default=0) + 1\n",
        "\n",
        "\n",
        "file_index = get_next_index(Combined_path)\n",
        "output_filename = f\"Combined_Sustain_text_{file_index}.txt\"\n",
        "output_path = os.path.join(Combined_path, output_filename)\n",
        "\n",
        "with open(output_path, \"w\", encoding=\"utf-8\") as outfile:\n",
        "    for filename in uploaded_Texts.keys():\n",
        "        with open(filename, \"r\", encoding=\"utf-8\", errors=\"ignore\") as infile:\n",
        "            content = infile.read()\n",
        "            paragraphs = split_paragraphs(content)\n",
        "            filtered_paragraphs = [para for para in paragraphs if contains_sustain_terms(para)]\n",
        "\n",
        "            if filtered_paragraphs:\n",
        "                outfile.write(f\"===== Start of File: {filename} =====\\n\")\n",
        "                for para in filtered_paragraphs:\n",
        "                    outfile.write(para + \"\\n\\n\")\n",
        "                outfile.write(f\"===== End of File: {filename} =====\\n\\n\")\n",
        "\n",
        "print(f\" پاراگراف‌های فیلتر شده ذخیره شدند در: {output_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEa3bHv4oyiI"
      },
      "outputs": [],
      "source": [
        "#Combined Files Together\n",
        "import glob\n",
        "\n",
        "merged_output_path = os.path.join(Combined_path, \"Combined_Sustain_MERGED.txt\")\n",
        "\n",
        "files_to_merge = sorted(\n",
        "    glob.glob(os.path.join(Combined_path, \"Combined_Sustain_text_*.txt\")),\n",
        "    key=lambda x: int(re.search(r\"_(\\d+)\\.txt$\", x).group(1))\n",
        ")\n",
        "\n",
        "with open(merged_output_path, \"w\", encoding=\"utf-8\") as outfile:\n",
        "    for file_path in files_to_merge:\n",
        "        with open(file_path, \"r\", encoding=\"utf-8\") as infile:\n",
        "            content = infile.read()\n",
        "            outfile.write(content + \"\\n\")\n",
        "\n",
        "print(f\" همه فایل‌ها با موفقیت ترکیب شدند.\\n مسیر فایل نهایی: {merged_output_path}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN00YfbiuM4LvDg6ca9dLhD",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}